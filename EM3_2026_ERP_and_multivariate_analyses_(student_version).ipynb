{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoHandzz/EM-google-colab/blob/main/EM3_2026_ERP_and_multivariate_analyses_(student_version).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSFgLOa1vNfw"
      },
      "source": [
        "#DEMO: ERP, statistics, and multivariate analyses"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset description\n",
        "\n",
        "The current data corresponds to an auditory mismatch negativity (MMN) experiment investigating the neural responses to unexpected sounds. It was recorded using the classical oddball paradigm in which a standard sound is repeated several times and is ocassionally interrupted by a deviant sound:\n",
        "\n",
        "A A A A A A B A A A A B A A A ....\n",
        "\n",
        "The participant listened to the sounds passively. These data belong to a collection of EEG datasets comprising some well-known event-related potentials (ERPs) used to study key cogntive functions. For more information, see:\n",
        "\n",
        "    Kappenman, E. S., Farrens, J. L., Zhang, W., Stewart, A. X., & Luck, S. J. (2021). ERP CORE: An open resource for human event-related potential research. NeuroImage, 225, 117465. https://doi.org/10.1016/j.neuroimage.2020.117465\n",
        "\n",
        "The goal of this analysis is to identify the differences in neural activity between expected and surprising sounds. These sounds are marked as different events in the EEG recording with the following codes:\n",
        "\n",
        "    standard: 80\n",
        "    deviant: 70\n",
        "\n",
        "Below you will be asked to solve a series of excercises by completing the code marked with ...\n",
        "\n",
        "For the analyses we will use the MNE-Python library.\n",
        "\n",
        "https://mne.tools/stable/index.html\n",
        "\n",
        "You can search each of the functions mentioned below in the documentation of the toolbox:\n",
        "\n",
        "https://mne.tools/stable/api/python_reference.html\n",
        "\n",
        "It is highly recommended not to use chatbots for this excercise. Just use your brain and the documentation above.\n",
        "\n",
        "Have fun!"
      ],
      "metadata": {
        "id": "_b5Y761CZeZ9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPs8d3aTvgME"
      },
      "source": [
        "#1. Initial setup\n",
        "\n",
        "First, we need to install and load the relevant Python packages as well as download the data from the web. Just run the following snippets of code by pressing the \"play\" icon on the left. This part will take a couple of minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lzZxWEkuvE8u"
      },
      "outputs": [],
      "source": [
        "!pip install mne==1.8.0 # installing the MNE toolbox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCsSFdxxwVE6"
      },
      "source": [
        "Load the libraries and setup plotting parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXN7Z78_v7yx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import mne\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# set size of raw browser\n",
        "mne.utils.config.set_config('MNE_BROWSE_RAW_SIZE','16.0,8.0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4i6IdKNu1Ff"
      },
      "source": [
        "These are some helper functions to browse raw data (just run the cell below)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39DBO4tk5C8h"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "def inspect_raw(craw,start, chan_sel,nchan=10,time_step=2,events=None):\n",
        "    order = np.arange(nchan, dtype = int) + int(nchan*(chan_sel-1))\n",
        "    order = order[order < len(raw.ch_names)]\n",
        "    cfig = craw.plot(events = events, start = start, duration = time_step,\n",
        "                     order = order,show_scrollbars = False)\n",
        "\n",
        "def raw_interact(craw, time_step = 2, nchan = 10, events=None):\n",
        "    _ = widgets.interact(inspect_raw,\n",
        "                     craw = widgets.fixed(craw),\n",
        "                     nchan = widgets.fixed(nchan),\n",
        "                     time_step = widgets.fixed(time_step),\n",
        "                     events = widgets.fixed(events),\n",
        "                     start = widgets.FloatSlider(value = 0,min = 0,max = raw.times[-1], step = time_step, description = 'time'),\n",
        "                     chan_sel = widgets.FloatSlider(value = 1, min = 1,step = 1, max = int(np.ceil(len(raw.ch_names)/nchan)),description = 'chan group'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obFo3bxVvw5a"
      },
      "source": [
        "Now we can download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cOfKoDjwL6w"
      },
      "outputs": [],
      "source": [
        "#!wget -O data.zip https://files.osf.io/v1/resources/5q4xs/providers/osfstorage/5f24a53fb084f6011ac9d604/?zip=\n",
        "!wget -O data.zip https://www.dropbox.com/scl/fo/z3xf96y5fk0t3z5sacvo7/ABslujmuCctLvYqQgLgDZK0?rlkey=abn3wwjmpp1oqc0n26b5ytq5z&dl=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysmEqGcev4xB"
      },
      "source": [
        "And exctract the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBd-b1Sxw1Pn"
      },
      "outputs": [],
      "source": [
        "!unzip data.zip\n",
        "!rm data.zip\n",
        "os.listdir(os.getcwd()) # verify that all files have been downloaded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7HkoEq628ei"
      },
      "source": [
        "#2. Loading and inspecting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylfj_2ka1hmC"
      },
      "outputs": [],
      "source": [
        "### Loading and setting up the raw data\n",
        "raw = mne.io.read_raw_eeglab('10_MMN.set', preload = True) # load the raw data\n",
        "\n",
        "# Some EOG channels were recorded to track eye movements. Here we label them:\n",
        "raw.set_channel_types({ch: 'eog' for ch in raw.ch_names if 'EOG' in ch})\n",
        "\n",
        "# Now we assign spatial electrode coordinates according to the 1020 system:\n",
        "raw.rename_channels({'FP1': 'Fp1','FP2': 'Fp2'}) # rename to coincide with 1020 system\n",
        "raw = raw.set_montage('standard_1020') # set the electrode positions (or montage)\n",
        "\n",
        "fig = raw.get_montage().plot()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of channels: {len(raw.ch_names)}\")\n",
        "print(f\"Sampling rate: {raw.info['sfreq']}\")\n",
        "print(f\"Channel names: {raw.ch_names}\")\n",
        "print(f\"Data shape: {raw.get_data().shape}\")"
      ],
      "metadata": {
        "id": "98fQVlxwu0jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpDQMbim1V62"
      },
      "source": [
        "Let's do some preprocessing.\n",
        "\n",
        "Often we record data at high temporal resolution. To make our analyses more efficient, we often reduce the sampling rate as shown below. Besides, we filter the data to get rid of slow drifts, high-frequency noise and power-line artifacts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qcbT2Uz2GRV"
      },
      "outputs": [],
      "source": [
        "raw = raw.resample(256) # Resample\n",
        "raw = raw.notch_filter(60) # Filter power line noise (60 Hz in the US, 50 Hz in Europe)\n",
        "raw = raw.filter(l_freq = 1, h_freq = 40)\n",
        "print(raw.info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEQN5-BWS7r2"
      },
      "source": [
        "Now we can use Independent Component Analysis (ICA) to to identify components in the data corresponding to eye movements.\n",
        "\n",
        "ICA finds components that are completely independent from each other, which allows them to capture meaningful patterns making them more interpretable.\n",
        "\n",
        "ICA has become the gold standard for the correction of EOG artifacts. In MNE,\n",
        "ICA can be easily implemented as shown below (this takes some time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOOyUqtTw9TQ"
      },
      "outputs": [],
      "source": [
        "ica = mne.preprocessing.ICA(random_state=42)\n",
        "ica.fit(raw.copy().pick('eeg'))\n",
        "ica.plot_components()\n",
        "ica.plot_sources(raw)\n",
        "raw_ica = ica.apply(raw.copy(),exclude= [0,4,5,13])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwedbnGd3m9A"
      },
      "source": [
        "Now we can have a look at the data, using the interactive function.\n",
        "We can control how long a segment and how many channels to display at once. Use the sliders to move around. What do you see?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oIvqcCAITHV"
      },
      "outputs": [],
      "source": [
        "raw_interact(raw,time_step=2,nchan=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3KmWE-b19ut"
      },
      "source": [
        "# Exercise 2.1 - Finding events of interest\n",
        "To be able to make comparisons of interest, we mark the times when interesting things happen. These times are called \"events\". In MNE, these events are represented in a N x 3 ndarray, with N events and event onset, duration and code represented in the first, second and third colum.\n",
        "\n",
        "In addition, we have an event_id dictionary indicating the mapping between our event names and their respective numeric codes.\n",
        "\n",
        "In this dataset, events are stored as 'annotations'. We need to retrieve them using the mne.events_from_annoations() function.\n",
        "\n",
        "* Print your array of events. What is the shape (or dimensions) of this array?\n",
        "* The first column of the array represents time stamps. What are its units?\n",
        "* How can we tell, in seconds, when an event happened? (Hint: use raw_ica.info['sfreq'])\n",
        "* What do the codes in column 3 represent? (Hint: look at the event_id dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvrVq-G-4oFS"
      },
      "outputs": [],
      "source": [
        "events, event_id = mne.events_from_annotations(raw_ica)\n",
        "\n",
        "# Event array\n",
        "for i, e in enumerate(events):\n",
        "  if i > 10:\n",
        "    break\n",
        "  print(e)\n",
        "\n",
        "# Shape of array\n",
        "print(events.shape)\n",
        "\n",
        "# Timestamps in seconds\n",
        "seconds = raw_ica.info['sfreq']\n",
        "print(seconds)\n",
        "\n",
        "# Identity of events\n",
        "print(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QlZ3wzJvBrz"
      },
      "source": [
        "Now we plot the data again with our events of interest marked.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUVsECpP6LNq"
      },
      "outputs": [],
      "source": [
        "raw_interact(raw_ica,nchan=20,events=events)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONMsZzbgVlK1"
      },
      "source": [
        "# 3. Event Related Potential (ERP) analyses\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZIyQX2TwU4p"
      },
      "source": [
        "One of the standard techniques in EEG research is to study the activity evoked by specific stimuli. We typically find the events of interest and average their waveforms. We call these responses Event Related Potentials or ERPs. Afterwards, we can compare the activity evoked by different stimuli or in different conditions to make inferences about cognitive processes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sRSrScm-Jwt"
      },
      "source": [
        "# Exercise 3.1. Re-referencing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-jJPU7RxBXg"
      },
      "source": [
        "Before looking further, we typically set a new reference for our EEG recordings. A popular choice is to take the average of all channels as reference.\n",
        "\n",
        "* Use the raw_ica.set_eeg_reference() method to set the reference to a channel (e.g., PO7) and plot the data. How did the signal change?\n",
        "* Use the same method to set the reference to \"average\". How did the signal change?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enECxJL9-NpF"
      },
      "outputs": [],
      "source": [
        "# We can change our referencing scheme\n",
        "raw_ref = raw_ica.set_eeg_reference(ref_channels='average')\n",
        "raw_interact(raw_ref, nchan=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sNyD66k9IMI"
      },
      "source": [
        "# Excercise 3.2. Epoching\n",
        "Now we need to cut our data into small pieces locked to the stimuli we are interested in. We cut epochs from -100 ms to 600 ms around stimulus onset.\n",
        "\n",
        "In addition, we will subtract from each epoch the mean activity during a baseline period between -100 ms and 0 ms. This is called \"baseline correction\" and allows us to reduce the impact of slow drifts in the data.\n",
        "\n",
        "Using the mne.Epochs function, obtain an Epochs class with data of the shape nevents x nchannels x ntimes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Fn33DX99ipE"
      },
      "outputs": [],
      "source": [
        "# Chunk the data into epochs\n",
        "tmin = -.2\n",
        "tmax = .6\n",
        "baseline = (-.1,0)\n",
        "epochs = mne.Epochs(raw_ica, preload=True, tmin = tmin, tmax=tmax, baseline=baseline)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the shape of the epochs data?\n",
        "How many timepoints are there?\n",
        "How many trials were averaged per condition?\n",
        "\n",
        "Hint: look at the attributes of the mne.Epochs class: https://mne.tools/stable/generated/mne.Epochs.html"
      ],
      "metadata": {
        "id": "5HibCN9zixrO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYY9OQ38F9Ic"
      },
      "outputs": [],
      "source": [
        "# Inspect the epochs\n",
        "print(epochs.info)\n",
        "print(epochs.get_data().shape)\n",
        "print(epochs.event_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4qgWMBuyZC7"
      },
      "source": [
        "After getting the epochs, we can now average the different conditions and store them in a dictionary. This is what we call an evoked response. Complete the code below to do that. Hint: use the epochs.average() method. You can index the condition of interest like this: epochs['70'].average()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "li6NYKST_Onr"
      },
      "outputs": [],
      "source": [
        "ERPs = {str(e): epochs[str(e)].average() for e in event_id}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfS6PNu3rkHR"
      },
      "source": [
        "Let's now inspect our two conditions. We will plot the EEG topographies at different times in the trial. When do interesting things happen? What differences do you see between standard and deviants?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJGVfNqnByH5"
      },
      "outputs": [],
      "source": [
        "#Standard sounds\n",
        "fig = ERPs['80'].plot_topomap(times=np.arange(-.1,.6,.1),show=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hPHA6nY_uzM"
      },
      "outputs": [],
      "source": [
        "# Deviant sounds\n",
        "fig = ERPs['70'].plot_topomap(times=np.arange(-.1,.6,.1),show=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeZfWYH0sYct"
      },
      "source": [
        "Now let's plot the ERP for a specific channel. For auditory MMN responses, we usually look at electrode Fz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBhGVvMeA0gn"
      },
      "outputs": [],
      "source": [
        "mne.viz.plot_compare_evokeds([ERPs['80'],ERPs['70']],picks=['Fz'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ugSW6n0szOF"
      },
      "source": [
        "The MMN is calculated as the difference between standard and deviants. We do that here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP601DtJAR8k"
      },
      "outputs": [],
      "source": [
        "ERPs['difference'] = mne.combine_evoked([ERPs['70'],ERPs['80']], weights=[1,-1])\n",
        "ERPs['difference'].comment = 'difference'\n",
        "\n",
        "# print(ERPs['difference'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4HXO0mss6Ra"
      },
      "source": [
        "# Excercise 3.3.\n",
        "\n",
        "Use the plot_compare_evokeds method to plot the MMN time course for electrode Fz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg-hhKQDFVBk"
      },
      "outputs": [],
      "source": [
        "fig = mne.viz.plot_compare_evokeds([ERPs['70'], ERPs['80'], ERPs['difference']], picks='Fz')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the plot_topomap method to plot the scalp topographies of the MMN:"
      ],
      "metadata": {
        "id": "2bGe_sDJj1LD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp112KW9HXJO"
      },
      "outputs": [],
      "source": [
        "fig = ERPs['70'].plot_topomap(times=0.200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfUmLm8itl8e"
      },
      "source": [
        "Let's explore another way of plotting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZGH1zF8IE6d"
      },
      "outputs": [],
      "source": [
        "ERPs['difference'].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpBjQIrGqZnG"
      },
      "source": [
        "# Excercise 3.4. (optional)\n",
        "\n",
        "Now let's compare it with a different reference scheme. Can you re-reference the epochs to channels ['P9','P10'] and plot the averages?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lPelAkeqhZr"
      },
      "outputs": [],
      "source": [
        "epochs2 = epochs.copy().set_eeg_reference(...)\n",
        "ERPs2 = {str(e): epochs2[e].average() for e in event_id}\n",
        "ERPs2['difference'] = ...\n",
        "ERPs2['difference'].comment = 'difference'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the averages below and compare with previous reference\n",
        "fig = ERPs['difference'].plot_topomap(times=np.arange(-.1,.6,.1),show=False)\n",
        "fig = ...\n"
      ],
      "metadata": {
        "id": "7rQ5Fa2C83kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Basic statistics\n",
        "\n",
        "For serious science, we cannot just trust our eyes. We need to also assess whether condition differences are statistically robust.\n",
        "\n",
        "EEG data is multidimensional. This makes statistical analysis difficult. Should we run a t-test for every single EEG channel and timepoint?\n",
        "\n",
        "Yes, but with caution. When we run so many tests on the same dataset, we are almost guaranteed to get a significant result for at least one time point and channel. Should we claim then that we made a discovery at 200 ms in channel 4?\n",
        "Not really. Most likely, this effect is simply due to random variation in the data. For more details on this, look at:\n",
        "\n",
        "* Luck, S.J. and Gaspelin, N. (2017), How to get statistically significant effects in any ERP experiment (and why you shouldn't). Psychophysiol, 54: 146-157. https://doi.org/10.1111/psyp.12639\n",
        "\n",
        "To avoid that, we need to handle the multiple comparison problem. There are many ways to do that. Here we will explore the simplest.\n",
        "\n"
      ],
      "metadata": {
        "id": "rJp1JlLskLMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4.1.\n",
        "\n",
        "Use the ttest_ind() function from the scipy library to run a t-test comparing standard sounds ('80') vs deviant sounds ('70') at each EEG channel and time point. You can look at the documentation of this function here:\n",
        "\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html\n",
        "\n",
        "Hint: To get the data for each condition you can use the epochs.get_data() method. For example: epochs['70'].get_data()"
      ],
      "metadata": {
        "id": "InX6sw8l-Srw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can do a t-test between conditions to find their differences\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "tvals, pvals = ttest_ind(epochs['80'].get_data(), epochs['70'].get_data())\n",
        "print(pvals.shape)\n"
      ],
      "metadata": {
        "id": "0IspIr8InC5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's find the channels and timepoints where differences were significant."
      ],
      "metadata": {
        "id": "a9MidHyQdU3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pmask = pvals <= .05\n",
        "print(pmask)"
      ],
      "metadata": {
        "id": "lcjUlEjqdUOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can plot the topographies with the statstically significant time-points and channels by passing our pmask to the mask parameter of the function:"
      ],
      "metadata": {
        "id": "l6LR9Z46e28o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot p-values\n",
        "fig = ERPs['difference'].plot_topomap(times=np.arange(0.1,.3,.02),show=False, mask=pmask)"
      ],
      "metadata": {
        "id": "Yp99z5Mfe_wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4.2.\n",
        "\n",
        "So far, we have not corrected for multiple comparisons. This means some of our statistical differences might be false positives due to multiple testing.\n",
        "\n",
        "We can correct for multiple comparisons with False Discovery Rate (FDR) correction, for example. Below we use the mne.stats.fdr_correction(pvals) with this purpose.\n",
        "\n",
        "* Compute the mask of FDR-corrected significant timepoints (qvals) and plot it using the example from the previous cell.\n",
        "* Did any of the significant points survive?\n",
        "* Do you think this method is being too conservative (i.e., missing true effects that are actually real)?\n"
      ],
      "metadata": {
        "id": "owLRTJ0ielsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, qvals = mne.stats.fdr_correction(pvals)\n",
        "qmask = qvals <= .05\n",
        "print(qmask)"
      ],
      "metadata": {
        "id": "jxWeG-JfduJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = ERPs['difference'].plot_topomap(times=np.arange(0.1,.3,.02),show=False, mask=qmask)"
      ],
      "metadata": {
        "id": "0Sp0UKInfVV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes, multiple comparison corrections will be too conservative. In that case you can use more principled ways to look at the effects that you are targetting. For example, you can average EEG activity for a specific time-window and channel chosen based on the literature and do statistic on these summary values. For the mismatch negativity, you can average from 150 to 250 ms of the electrode Fz.\n",
        "\n",
        "We can do that below for one of our conditions.\n"
      ],
      "metadata": {
        "id": "vKK3VqSvfwvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_index = (epochs.times >= 0.15) & (epochs.times <= 0.25) # Get time window\n",
        "standard_means = epochs['80'].copy().pick('Fz').get_data()[:,:,time_index].mean(axis=-1)[:,0]\n",
        "print(standard_means.shape)"
      ],
      "metadata": {
        "id": "pAnc4AsOCZb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4.3.\n",
        "\n",
        "Get mean amplitude values for the deviant sound ('70') and do a t-test using the ttest_ind function that you used before. Is there a significant difference between standard and deviant?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9mHzJFT0DtKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deviant_means = epochs['70'].get_data()\n",
        "print(deviant_means.shape)"
      ],
      "metadata": {
        "id": "iRqVc-_8En9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tval, pval = ttest_ind(deviant_means)\n",
        "print(f't = {tval}, p = {pval}')"
      ],
      "metadata": {
        "id": "LilDojW3Etl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, another approach that makes less assumptions about the data is cluster-based permutations:\n",
        "\n",
        "https://mne.tools/stable/auto_tutorials/stats-sensor-space/50_cluster_between_time_freq.html"
      ],
      "metadata": {
        "id": "zs7Ju3gjCMVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Multivariate Pattern Analysis, Machine learning and Decoding"
      ],
      "metadata": {
        "id": "Ms00qv2Chm2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes, EEG data can have rich patterns of activity across channels and time that are difficult to capture with conventional ERP analyses. To properly study them, we can use multivariate pattern analysis which employs machine learning techniques to discover how patterns of brain activity are related to stimuli and variables of interest.\n",
        "\n",
        "One popular approach is to try to decode the identity of perceived stimuli from brain activity. Below, we will use this approach to predict whether the participant heard a standard ('80') or a deviant ('70') sound.\n",
        "\n",
        "We will use logistic regression for this purpose, using the scikitlearn library. For details about this function, see here:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "Moreover, MNE has an mne.decoding library with useful functions to handle multidimensional data such as EEG.\n",
        "\n",
        "In particular, the SlidingEstimator allows us to fit and test a decoding model for each time point of the epochs.\n",
        "\n",
        "First, we load the necessary libraries.\n"
      ],
      "metadata": {
        "id": "oNOJfl25GWdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from mne.decoding import (\n",
        "    LinearModel,\n",
        "    Scaler,\n",
        "    SlidingEstimator,\n",
        "    cross_val_multiscore,\n",
        "    get_coef)\n"
      ],
      "metadata": {
        "id": "F2CYAMaxhmJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we get our data.\n",
        "\n",
        "* What are the dimension of the data matrix X?\n",
        "* What are the dimesions of the class labels vector y?"
      ],
      "metadata": {
        "id": "xQmul_EgLYWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = epochs.copy().pick('eeg').get_data()[epochs.events[:,2]>2]  # EEG signals: n_epochs, n_channels, n_times\n",
        "y = epochs.events[epochs.events[:,2]>2, 2]  # standard (4) vs deviant (3)\n",
        "\n",
        "# We recode the deviants so that standard = 0 and deviant = 3\n",
        "y = y*-1 + 4\n",
        "\n",
        "# Now we get de dimensions\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "ZsZHgo7wiN6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we build our classification pipeline which consists of two steps:\n",
        "\n",
        "1- Standardize the data by subtracting the mean and dividing by the standard deviation of each EEG channel (StandardScaler).\n",
        "\n",
        "2- Fit the LogisticRegression.\n",
        "\n",
        "At the end, we evaluate our model using 5-fold cross-validation (cross_val_multiscore)"
      ],
      "metadata": {
        "id": "uvoFUoBmL9BP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we make a classifier:\n",
        "clf = make_pipeline(StandardScaler(), LinearModel(LogisticRegression(solver=\"liblinear\")))\n",
        "decoder = SlidingEstimator(clf, n_jobs=-1, scoring=\"roc_auc\", verbose=True)\n",
        "scores = cross_val_multiscore(decoder, X, y, cv=KFold(n_splits=5,shuffle=True), n_jobs=None)"
      ],
      "metadata": {
        "id": "rqhHMRWLielQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can plot the performance of the model at each time point below. When is the accuracy highest?"
      ],
      "metadata": {
        "id": "vCaSule0M6BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(epochs.times, scores.mean(0), label=\"score\")\n",
        "ax.axhline(0.5, color=\"k\", linestyle=\"--\", label=\"chance\")\n",
        "ax.set_xlabel(\"Times\")\n",
        "ax.set_ylabel(\"AUC\")  # Area Under the Curve\n",
        "ax.legend()\n",
        "ax.axvline(0.0, color=\"k\", linestyle=\"-\")\n",
        "ax.set_title(\"Sensor space decoding\")"
      ],
      "metadata": {
        "id": "u18-wLMKi_kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Exercise 5.1.\n",
        "\n",
        " In decoding analyses, it is very important to never train and test your model with the same data. Otherwise, your model will overfit and give you a wrong impression of the true performance of the model.\n",
        "\n",
        "* Just for fun, train and test the model on the same data and labels, and plot the accuracy using the same figure as before. How does the accuracy change? Hint: use the decoder.score() method."
      ],
      "metadata": {
        "id": "vu4LVcocQofM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder.fit(X,y)\n",
        "overfit = ..."
      ],
      "metadata": {
        "id": "fkwpHwLdReAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(epochs.times, scores.mean(0), label=\"cross-validation score\")\n",
        "ax.plot(..., label=\"overfit score\")\n",
        "ax.axhline(0.5, color=\"k\", linestyle=\"--\", label=\"chance\")\n",
        "ax.set_xlabel(\"Times\")\n",
        "ax.set_ylabel(\"AUC\")  # Area Under the Curve\n",
        "ax.legend()\n",
        "ax.axvline(0.0, color=\"k\", linestyle=\"-\")\n",
        "ax.set_title(\"Sensor space decoding\")"
      ],
      "metadata": {
        "id": "Ir7flmPFRnFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  # Bonus: Coefficient interpretation."
      ],
      "metadata": {
        "id": "g9L-2LQtNG1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can inspect the coefficients of our model to understand what patterns of activity distinguish one condition from another.\n",
        "\n",
        "Note that model coefficients are not directly interpretable in terms of physiology. However, they can be transformed into patterns of activity as shown below.\n",
        "\n",
        "See this paper for more info:\n",
        "\n",
        "Stefan Haufe, Frank Meinecke, Kai Görgen, Sven Dähne, John-Dylan Haynes, Benjamin Blankertz, and Felix Bießmann. On the interpretation of weight vectors of linear models in multivariate neuroimaging. NeuroImage, 87:96–110, 2014. doi:10.1016/j.neuroimage.2013.10.067.\n",
        "\n",
        "How to these patterns compare to the MMN difference wave that we calculated above?"
      ],
      "metadata": {
        "id": "IMZbWGycX5M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpreting the coefficients:\n",
        "decoder.fit(X,y)\n",
        "patterns = get_coef(decoder,inverse_transform=True,attr='patterns_')"
      ],
      "metadata": {
        "id": "v6j3ZSxSreg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evoked_time_gen = mne.EvokedArray(patterns, epochs.copy().pick('eeg').info, tmin=epochs.times[0])\n",
        "joint_kwargs = dict(ts_args=dict(time_unit=\"s\"), topomap_args=dict(time_unit=\"s\"))\n",
        "evoked_time_gen.plot_joint(\n",
        "    times=np.arange(-.1,.6,.1),show=False, title=\"patterns\"\n",
        ")"
      ],
      "metadata": {
        "id": "pYtwZwG5t4dP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}